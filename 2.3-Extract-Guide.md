## EXTRACT
So here's a problem. We have a ton of pictures of both our subjects, but they're just pictures of them doing stuff or in an environment with other people. Their bodies are on there, they're on there with other people... It's a mess. We can only train our bot if the data we have is consistent and focusses on the subject we want to swap. This is where faceswap first comes in.

```bash
# To convert trump:
python faceswap.py extract -i ~/faceswap/photo/trump -o ~/faceswap/data/trump
# To convert cage:
python faceswap.py extract -i ~/faceswap/photo/cage -o ~/faceswap/data/cage
```

We specify our photo input directory and the output folder where our training data will be saved. The script will then try its best to recognize face landmarks, crop the image to that size, and save it to the output folder. Note: this script will make grabbing test data much easier, but it is not perfect. It will (incorrectly) detect multiple faces in some photos and does not recognize if the face is the person who we want to swap. Therefore: **Always check your training data before you start training.** The training data will influence how good your model will be at swapping.

You can see the full list of arguments for extracting via help flag. i.e.

```bash
python faceswap.py extract -h
```


My Extract workflow generally goes:
- Extract - MTCNN (rotate on)
- Alignments tool sort-x (Index the faces left to right)
- Alignments tool multi-faces with move output
- Go through the output folders removing unwanted faces/false positives
- Put the faces back into the main output folder
- Alignments tool remove-faces to remove the faces I deleted from the alignments file 
- Alignments tool manual - Fix misaligned/missing landmarks
- Delete my faces output folder then run Alignments tool extract or extract-large depending on what I want to do next. 